{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to duplicate ARGOG using cells \n",
    "## code is from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade llama-index\n",
    "# !pip show llama-index\n",
    "\n",
    "# !pip install llama-index-agent-openai  llama-index-cli  llama-index-core  llama-index-embeddings-openai  llama-index-indices-managed-llama-cloud  llama-index-legacy  llama-index-llms-openai  llama-index-multi-modal-llms-openai  llama-index-program-openai  llama-index-question-gen-openai  llama-index-readers-file  llama-index-readers-llama-parse  nltk\n",
    "# !pip install -U llama-index\n",
    "# %pip install -q cohere llama-index-postprocessor-cohere-rerank\n",
    "# !pip install tonic-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stuff\n",
    "import openai\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from utils import run_experiment, load_config\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, PromptTemplate, ServiceContext, Settings\n",
    "# from llama_index.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from tonic_validate import ValidateScorer, ValidateApi\n",
    "from tonic_validate.metrics import RetrievalPrecisionMetric, AnswerSimilarityMetric\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample code to use tonic validate\n",
    "# from tonic_validate import Benchmark, ValidateApi, ValidateScorer\n",
    "\n",
    "# # Function to simulate getting a response and context from your LLM\n",
    "# # Replace this with your actual function call\n",
    "# def get_rag_response(question):\n",
    "#     return {\n",
    "#         \"llm_answer\": \"Paris\",\n",
    "#         \"llm_context_list\": [\"Paris is the capital of France.\"]\n",
    "#     }\n",
    "\n",
    "# benchmark = Benchmark(questions=[\"What is the capital of France?\"], answers=[\"Paris\"])\n",
    "# # Score the responses for each question and answer pair\n",
    "# scorer = ValidateScorer()\n",
    "# run = scorer.score(benchmark, get_rag_response)\n",
    "# validate_api = ValidateApi(\"opycxzKWmtHosC25-r_Kd31EbfLHVBerNEBj675AeS4\")\n",
    "# validate_api.upload_run(\"f6cd8c02-2ef3-42ac-bc69-6c2fd5e3df03\", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP --------------------------------------------------------------------------------------------------------------\n",
    "# Load the config file (.env vars)\n",
    "load_config()\n",
    "# load_dotenv(override=True)\n",
    "# Set the OpenAI API key for authentication.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tonic_validate_api_key = os.getenv(\"HASSAN_TONIC_VALIDATE_API1\")\n",
    "tonic_validate_project_key = os.getenv(\"HASSAN_TONIC_VALIDATE_PROJECT1\")\n",
    "tonic_validate_benchmark_key = os.getenv(\"HASSAN_TONIC_VALIDATE_BENCHMARK1\")\n",
    "validate_api = ValidateApi(tonic_validate_api_key)\n",
    "# print (f'{tonic_validate_api_key} {tonic_validate_project_key} {tonic_validate_benchmark_key}')\n",
    "cohere_api_key = os.getenv(\"HASSAN_COHERE_DEFAULT_API\")\n",
    "# print (f'{tonic_validate_api_key} {tonic_validate_project_key} {tonic_validate_benchmark_key}')\n",
    "# cohere_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config into dictionary\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Create a config dictionary\n",
    "config = {\n",
    "    # 'cohere_api_key': os.getenv('COHERE_API_KEY'),\n",
    "    # 'another_setting': os.getenv('ANOTHER_SETTING'),\n",
    "    'tonic_validate_api_key': os.getenv(\"HASSAN_TONIC_VALIDATE_API1\"),\n",
    "    'tonic_validate_project_key':  os.getenv(\"HASSAN_TONIC_VALIDATE_PROJECT1\"),\n",
    "    'tonic_validate_benchmark_key':  os.getenv(\"HASSAN_TONIC_VALIDATE_BENCHMARK1\"),\n",
    "    'cohere_api_key':  os.getenv(\"HASSAN_COHERE_DEFAULT_API\")\n",
    "}\n",
    "\n",
    "# Print to verify\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service context\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "# service_context = ServiceContext.from_defaults(llm = llm, embed_model = embed_model)\n",
    "# settings = Settings(llm=llm, embed_model=embed_model)\n",
    "Settings.llm = llm \n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # existing_collections = chroma_client.list_collections()\n",
    "# # print(existing_collections)\n",
    "# # First, check if collection exists and create it if it doesn't\n",
    "# try:\n",
    "#     chroma_collection = chroma_client.get_collection(\"ai_arxiv_full\")\n",
    "# except:\n",
    "#     # Create new collection\n",
    "#     chroma_collection = chroma_client.create_collection(\n",
    "#         name=\"ai_arxiv_full\",\n",
    "#         metadata={\"description\": \"ArXiv AI papers collection\"}\n",
    "#     )\n",
    "\n",
    "# # Now you can use the collection\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "# from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "# from llama_index.core.node_parser import SentenceWindowNodeParser  # Updated import path\n",
    "\n",
    "# # Create the collection first\n",
    "# try:\n",
    "#     chroma_collection_sentence_window = chroma_client.get_collection(\"ai_arxiv_sentence_window\")\n",
    "# except:\n",
    "#     chroma_collection_sentence_window = chroma_client.create_collection(\n",
    "#         name=\"ai_arxiv_sentence_window\",\n",
    "#         metadata={\"description\": \"ArXiv AI papers with sentence window processing\"}\n",
    "#     )\n",
    "\n",
    "# # Set up sentence window processing\n",
    "# node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "#     window_size=3,\n",
    "#     window_metadata_key=\"window\",\n",
    "#     original_text_metadata_key=\"original_text\"\n",
    "# )\n",
    "\n",
    "# # Update settings with the node parser\n",
    "# Settings.node_parser = node_parser\n",
    "\n",
    "# # Set up vector store and index\n",
    "# vector_store_sentence_window = ChromaVectorStore(\n",
    "#     chroma_collection=chroma_collection_sentence_window\n",
    "# )\n",
    "# storage_context = StorageContext.from_defaults(\n",
    "#     vector_store=vector_store_sentence_window\n",
    "# )\n",
    "\n",
    "# # Create the index\n",
    "# index_sentence_window = VectorStoreIndex.from_vector_store(\n",
    "#     vector_store=vector_store_sentence_window\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional VDB\n",
    "chroma_collection = chroma_client.get_collection(\"ai_arxiv_full\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window VDB\n",
    "chroma_collection_sentence_window = chroma_client.get_collection(\"ai_arxiv_sentence_window\")\n",
    "vector_store_sentence_window = ChromaVectorStore(chroma_collection=chroma_collection_sentence_window)\n",
    "index_sentence_window = VectorStoreIndex.from_vector_store(vector_store=vector_store_sentence_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document summary VDB\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage_context = StorageContext.from_defaults(persist_dir=\"Obelix\")\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"ai_arxiv_doc_summary\")\n",
    "doc_summary_index = load_index_from_storage(llm=llm,\n",
    "                                              storage_context=storage_context,\n",
    "                                             embed_model = embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "with open(\"resources/text_qa_template.txt\", 'r', encoding='utf-8') as file:\n",
    "    text_qa_template_str = file.read()\n",
    "\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tonic Validate setup\n",
    "benchmark = validate_api.get_benchmark(tonic_validate_benchmark_key)\n",
    "scorer = ValidateScorer(metrics=[RetrievalPrecisionMetric(), AnswerSimilarityMetric()],\n",
    "                        model_evaluator=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define query engines -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive RAG\n",
    "query_engine_naive = index.as_query_engine(llm = llm,\n",
    "                                           text_qa_template=text_qa_template,\n",
    "                                           similarity_top_k=3,\n",
    "                                           embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohere Rerank\n",
    "cohere_rerank = CohereRerank(api_key=config['cohere_api_key'], top_n=3)  # Ensure top_n matches k in naive RAG for comparability\n",
    "query_engine_rerank = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    "    llm = llm,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE\n",
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "query_engine_hyde = TransformQueryEngine(query_engine_naive, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE + Cohere Rerank\n",
    "query_engine_hyde_rerank = TransformQueryEngine(query_engine_rerank, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal Marginal Relevance (MMR)\n",
    "query_engine_mmr = index.as_query_engine(vector_store_query_mode=\"mmr\",\n",
    "                                         similarity_top_k=3,\n",
    "                                          embed_model=embed_model,\n",
    "                                          llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query\n",
    "vector_retriever = index.as_retriever(similarity_top_k=3)\n",
    "retriever_multi_query = QueryFusionRetriever(\n",
    "    [vector_retriever],\n",
    "    similarity_top_k=3,\n",
    "    num_queries=5,\n",
    "    llm=llm,\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=False,\n",
    "    verbose=True\n",
    ")\n",
    "query_engine_multi_query = RetrieverQueryEngine.from_args(retriever_multi_query,\n",
    "                                                          verbose=True,\n",
    "                                                          embed_model=embed_model,\n",
    "                                                          llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query + Cohere rerank + simple fusion\n",
    "retriever_multi_query_rerank = QueryFusionRetriever(\n",
    "    [vector_retriever],\n",
    "    similarity_top_k=10,\n",
    "    llm=llm,\n",
    "    num_queries=5,\n",
    "    mode=\"simple\",\n",
    "    use_async=False,\n",
    "    verbose=True\n",
    ")\n",
    "query_engine_multi_query_rerank = RetrieverQueryEngine.from_args(retriever_multi_query_rerank,\n",
    "                                                                 verbose=True,\n",
    "                                                                 node_postprocessors=[cohere_rerank],\n",
    "                                                                 embed_model=embed_model,\n",
    "                                                                 llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM Rerank\n",
    "llm_rerank = LLMRerank(choice_batch_size=10, top_n=3)\n",
    "query_engine_llm_rerank = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[llm_rerank],\n",
    "    embed_model=embed_model,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE + LLM Rerank\n",
    "query_engine_hyde_llm_rerank = TransformQueryEngine(query_engine_llm_rerank, hyde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval\n",
    "query_engine_sentence_window = index_sentence_window.as_query_engine(text_qa_template=text_qa_template,\n",
    "                                                                     similarity_top_k=3,\n",
    "                                                                      embed_model=embed_model,\n",
    "                                                                      llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval + Cohere rerank\n",
    "query_engine_sentence_window_rerank = index_sentence_window.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    "    embed_model=embed_model,\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval + LLM Rerank\n",
    "query_engine_sentence_window_llm_rerank = index_sentence_window.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[llm_rerank],\n",
    "    embed_model=embed_model,\n",
    "    llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval + HyDE\n",
    "query_engine_sentence_window_hyde = TransformQueryEngine(query_engine_sentence_window, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval + HyDE + Cohere Rerank\n",
    "query_engine_sentence_window_hyde_rerank = TransformQueryEngine(query_engine_sentence_window_rerank, hyde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window retrieval + HyDE + LLM Rerank\n",
    "query_engine_sentence_window_hyde_llm_rerank = TransformQueryEngine(query_engine_sentence_window_llm_rerank, hyde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document summary index + Cohere Rerank\n",
    "query_engine_doc_summary_rerank = doc_summary_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    "    llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document summary index + HyDE + Cohere Rerank\n",
    "query_engine_hyde_doc_summary_rerank = TransformQueryEngine(query_engine_doc_summary_rerank, hyde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run experiments -------------------------------------------------------------------------------------------------------\n",
    "# Dictionary of experiments, now referencing the predefined query engine objects\n",
    "experiments = {\n",
    "    # \"Classic VDB + Naive RAG\": query_engine_naive,\n",
    "    # \"Classic VDB + Cohere Rerank\": query_engine_rerank,\n",
    "    # \"Classic VDB + LLM Rerank\": query_engine_llm_rerank,\n",
    "    # \"Classic VDB + HyDE\": query_engine_hyde,\n",
    "    # \"Classic VDB + HyDE + Cohere Rerank\": query_engine_hyde_rerank,\n",
    "    # \"Classic VDB + HyDE + LLM Rerank\": query_engine_hyde_llm_rerank,\n",
    "    # \"Classic VDB + Maximal Marginal Relevance (MMR)\": query_engine_mmr,\n",
    "    # \"Classic VDB + Multi Query + Reciprocal\": query_engine_multi_query,\n",
    "    # \"Classic VDB + Multi Query + Cohere rerank\": query_engine_multi_query_rerank,\n",
    "    # \"Sentence window retrieval\": query_engine_sentence_window,\n",
    "    # \"Sentence window retrieval + Cohere rerank\": query_engine_sentence_window_rerank,\n",
    "    # \"Sentence window retrieval + LLM Rerank\": query_engine_sentence_window_llm_rerank,\n",
    "    # \"Sentence window retrieval + HyDE\": query_engine_sentence_window_hyde,\n",
    "    # \"Sentence window retrieval + HyDE + Cohere Rerank\": query_engine_sentence_window_hyde_rerank,\n",
    "    \"Sentence window retrieval + HyDE + LLM Rerank\": query_engine_sentence_window_hyde_llm_rerank,\n",
    "    # \"Document summary index + Cohere Rerank\": query_engine_doc_summary_rerank,\n",
    "    # \"Document summary index + HyDE + Cohere Rerank\": query_engine_hyde_doc_summary_rerank\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to collect results from all experiments\n",
    "all_experiments_results_df = pd.DataFrame(columns=['Run', 'Experiment', 'OverallScores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses: 0it [00:00, ?it/s]\n",
      "Scoring responses: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence window retrieval + HyDE + LLM Rerank Run 1 Overall Scores: {}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "422 Client Error: Unprocessable Entity for url: https://validate.tonic.ai/api/v1/projects/opycxzKWmtHosC25-r_Kd31EbfLHVBerNEBj675AeS4/runs/with_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loop through each experiment configuration, run it, and collect results\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment_name, query_engine \u001b[38;5;129;01min\u001b[39;00m experiments\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m     experiment_results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mquery_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mvalidate_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtonic_validate_project_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust the number of runs as needed\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Append the results of this experiment to the master DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     all_experiments_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_experiments_results_df, experiment_results_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\Dropbox\\GithubRepo\\StanfordContinuingStudies\\TECH14LLMProduction\\ARAGOG\\utils.py:65\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(experiment_name, query_engine, scorer, benchmark, validate_api, project_key, upload_results, runs)\u001b[0m\n\u001b[0;32m     62\u001b[0m results_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m'\u001b[39m: i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m'\u001b[39m: experiment_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallScores\u001b[39m\u001b[38;5;124m'\u001b[39m: run\u001b[38;5;241m.\u001b[39moverall_scores})\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m upload_results:\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mvalidate_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapproach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_number\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping upload for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\envs\\ARAGOG\\lib\\site-packages\\pydantic\\validate_call_decorator.py:60\u001b[0m, in \u001b[0;36mvalidate_call.<locals>.validate.<locals>.wrapper_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(function)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_call_wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\envs\\ARAGOG\\lib\\site-packages\\pydantic\\_internal\\_validate_call.py:96\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 96\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\envs\\ARAGOG\\lib\\site-packages\\tonic_validate\\validate_api.py:65\u001b[0m, in \u001b[0;36mValidateApi.upload_run\u001b[1;34m(self, project_id, run, run_metadata, tags)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_evaluator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m run_metadata:\n\u001b[0;32m     64\u001b[0m     run_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_evaluator\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39mllm_evaluator\n\u001b[1;32m---> 65\u001b[0m run_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/projects/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs/with_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_metadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrun_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\envs\\ARAGOG\\lib\\site-packages\\tonic_validate\\utils\\http_client.py:76\u001b[0m, in \u001b[0;36mHttpClient.http_post\u001b[1;34m(self, url, params, data, timeout)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make a post request.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Passed as the data parameter of the requests.post request.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url \u001b[38;5;241m+\u001b[39m url,\n\u001b[0;32m     70\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\envs\\ARAGOG\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: https://validate.tonic.ai/api/v1/projects/opycxzKWmtHosC25-r_Kd31EbfLHVBerNEBj675AeS4/runs/with_data"
     ]
    }
   ],
   "source": [
    "# Loop through each experiment configuration, run it, and collect results\n",
    "for experiment_name, query_engine in experiments.items():\n",
    "    experiment_results_df = run_experiment(experiment_name,\n",
    "                                            query_engine,\n",
    "                                            scorer,\n",
    "                                            benchmark,\n",
    "                                            validate_api,\n",
    "                                            config['tonic_validate_project_key'],\n",
    "                                            upload_results=True,\n",
    "                                            runs=10)  # Adjust the number of runs as needed\n",
    "\n",
    "    # Append the results of this experiment to the master DataFrame\n",
    "    all_experiments_results_df = pd.concat([all_experiments_results_df, experiment_results_df], ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARAGOG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
